{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ticket_id\n284932    0.057993\n285362    0.007384\n285361    0.075421\n285338    0.058295\n285346    0.074732\n            ...   \n376496    0.007332\n376497    0.007332\n376499    0.074383\n376500    0.074382\n369851    0.112515\nName: compliance, Length: 61001, dtype: float64"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def blight_model(): \n",
    "    \n",
    "    \n",
    "    X_train = pd.read_csv(\"train.csv\", encoding = 'ISO-8859-1' )\n",
    "    X_test = pd.read_csv(\"test.csv\", encoding = 'ISO-8859-1' )\n",
    "    \n",
    "    # Preprocessing of data sets\n",
    "\n",
    "    X_train = X_train[(X_train['compliance'] == 0) | (X_train['compliance'] == 1)]\n",
    "    addresses = pd.read_csv('addresses.csv')\n",
    "    latlons = pd.read_csv('latlons.csv')\n",
    "    \n",
    "    # Joining addresses to latitude and longitude\n",
    "\n",
    "    addresses = addresses.set_index('address')\n",
    "    latlons = latlons.set_index('address')\n",
    "    addresses = addresses.join(latlons, how='left')\n",
    "    addresses = addresses.set_index('ticket_id')\n",
    "    \n",
    "    # Joining to train and test data\n",
    "\n",
    "    X_train = X_train.set_index('ticket_id')\n",
    "    X_test = X_test.set_index('ticket_id')\n",
    "    X_train = X_train.join(addresses, how='left')\n",
    "    X_test = X_test.join(addresses, how='left') \n",
    "    y_train = X_train[['compliance']]\n",
    "    \n",
    "    # Filling NULL values\n",
    "\n",
    "    X_train.lat.fillna(method='pad', inplace=True)\n",
    "    X_train.lon.fillna(method='pad', inplace=True)\n",
    "    X_train.state.fillna(method='pad', inplace=True)\n",
    "\n",
    "    X_test.lat.fillna(method='pad', inplace=True)\n",
    "    X_test.lon.fillna(method='pad', inplace=True)\n",
    "    \n",
    "    # Data Leakage \n",
    "\n",
    "    train_leaks = [\n",
    "        'balance_due',\n",
    "        'collection_status',\n",
    "        'compliance_detail',\n",
    "        'payment_amount',\n",
    "        'payment_date',\n",
    "        'payment_status', \n",
    "        'compliance'\n",
    "    ]\n",
    "    \n",
    "    # Columns with no information\n",
    "\n",
    "    no_info_columns = ['agency_name', 'violation_street_number', 'mailing_address_str_number',\n",
    "                      'state', 'disposition', 'violator_name', 'zip_code', 'country', 'city',\n",
    "                      'inspector_name', 'violation_street_name', 'violation_zip_code',\n",
    "                      'violation_description', 'mailing_address_str_name', 'non_us_str_code',\n",
    "                      'ticket_issued_date', 'hearing_date', 'violation_code', 'grafitti_status']\n",
    "    \n",
    "    X_train.drop(train_leaks, inplace=True, axis=1)\n",
    "    X_train.drop(no_info_columns, inplace= True, axis=1)\n",
    "    X_test.drop(no_info_columns, inplace=True, axis=1)\n",
    "    \n",
    "    clfLR = LogisticRegression().fit(X_train, y_train)\n",
    "    # regr_rf = RandomForestRegressor()\n",
    "    \n",
    "    test_proba = clfLR.predict_proba(X_test)[:,1]\n",
    "    X_test['compliance'] = test_proba\n",
    "        \n",
    "    # Using Grid Search to find optimal values for finding optimal values\n",
    "\n",
    "    #grid_values = {'C': [0.001]}\n",
    "    #grid_clf_auc = GridSearchCV(clfLR, param_grid = grid_values, scoring = 'roc_auc')\n",
    "    #grid_clf_auc.fit(X_train, y_train)\n",
    "    \n",
    "    \n",
    "    # grid_values = {'n_estimators': [10, 100], 'max_depth': [None, 30]}\n",
    "    # grid_clf_auc = GridSearchCV(regr_rf, param_grid=grid_values, scoring='roc_auc')\n",
    "    # grid_clf_auc.fit(X_train, y_train)\n",
    "    # print('Grid best score (AUC): ', grid_clf_auc.best_score_)\n",
    "    # print('Grid best parameter (max. AUC): ', grid_clf_auc.best_params_)\n",
    "    \n",
    "    return X_test.compliance\n",
    "\n",
    "\n",
    "blight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "ticket_id\n284932    0.057993\n285362    0.007384\n285361    0.075421\n285338    0.058295\n285346    0.074732\n            ...   \n376496    0.007332\n376497    0.007332\n376499    0.074383\n376500    0.074382\n369851    0.112515\nName: compliance, Length: 61001, dtype: float64"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "blight_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'clfLR' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-cf4903c58fe1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# accuracy is the default scoring metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross-validation (accuracy)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclfLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clfLR' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# accuracy is the default scoring metric\n",
    "print('Cross-validation (accuracy)', cross_val_score(clfLR, X_train, y_train, cv=5))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}